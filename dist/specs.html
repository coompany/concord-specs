<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="acidghost">
  <title>Concord</title>
  <style type="text/css">code{white-space: pre;}</style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header>
<h1 class="title">Concord</h1>
<h1 class="subtitle">A Distributed Voting Protocol</h1>
<h2 class="author">acidghost</h2>
</header>
<h2 id="network-protocol">Network Protocol</h2>
<p>Based on <em>Kademlia</em> <span class="citation" data-cites="maymounkov2002kademlia">(Maymounkov and Mazieres 2002)</span> and its extension <em>S/Kademlia</em> <span class="citation" data-cites="baumgart2007s">(Baumgart and Mies 2007)</span>. Each node is identified by a <code>nodeId</code> which is computed using a crypto puzzle. The puzzle generates also a key pair that is used to sign and verify integrity of messages.</p>
<p>Kademlia uses four RPCs for node / value lookup, routing table maintenance and storing values in the DHT:</p>
<ul>
<li><code>ping</code>: usual ping / pong request to check liveness of nodes;</li>
<li><code>store</code>: instructs the target node to store a <code>(key, value)</code> pair;</li>
<li><code>find_node</code>: takes a <code>nodeId</code> as an argument and the recipient of the request returns a list of <span class="math inline"><em>k</em></span> triples <code>(IPaddr, UDPport, nodeId)</code> of nodes closest to the queried <code>nodeId</code>;</li>
<li><code>find_value</code>: behaves like <code>find_node</code> with the exception that if the target node has previously received a <code>store</code> request for the target key, it will return the stored value directly.</li>
</ul>
<p>At the moment Concord implements only <code>ping</code> and <code>find_node</code> RPCs. This is because the other ones seem related to a file-sharing application. The future development of the voting protocol will tell us if and in what extent Concord will need to implement <code>store</code> and <code>find_value</code> procedures.</p>
<p>Nodes are stored in a <em>DHT</em> (Distributed Hash Table). The local DHT is organized in <em>k-buckets</em>. For each bit in the <code>nodeId</code>, a node maintains a k-bucket, that is a FIFO list of nodes sorted with a last-seen policy (least recently seen node at the head). Let be <span class="math inline"><em>n</em></span> the number of bits in the <code>nodeId</code>. Each node maintains <span class="math inline"><em>n</em></span> k-buckets and each of them contains nodes at distance between <span class="math inline">2<sup><em>i</em></sup></span> and <span class="math inline">2<sup><em>i</em> + 1</sup></span> <span class="math inline">∀<em>i</em> ∈ {0, ..., <em>n</em> − 1}</span>.</p>
<p><img src="graphviz-images/9cd4bbf1d4dd5d072de649081fb585394610eeb4.png" alt="" include="graphs/kademlia.dot" prog="dot" /></p>
<p>In the above Figure, we show Kademlia's DHT for nodeId <code>1100</code> in a network where the ID space is in 4 bits. Each color corresponds to a different k-bucket's range. In each k-bucket node IDs can be present or not (in the Figure, all nodes are shown as present) and each node maintains locally a list of <span class="math inline"><em>k</em></span> nodes for each bucket. Note also that each k-bucket is responsible for progressively twice the number of node IDs when moving away from the local node's ID, that is <span class="math inline"><em>n</em><sub><em>i</em></sub> = 2<em>n</em><sub><em>i</em> − 1</sub>∀<em>i</em> ∈ {1, ..., <em>n</em> − 1}</span> and <span class="math inline"><em>n</em><sub>0</sub> = 1</span> where <span class="math inline"><em>n</em><sub><em>i</em></sub></span> is the number of possible node IDs in bucket <span class="math inline"><em>i</em></span>. By moving away from the current node ID, each k-bucket covers twice the number of node IDs.</p>
<h2 id="voting-protocol">Voting Protocol</h2>
<p>The goal of this protocol is to allow anyone to create a poll and collect opinions on it. Each node is itself a voter and everyone is free to participate in the voting process. Each voter is also responsible of verification of votes and votes counting.</p>
<h3 id="starting-a-poll">Starting a Poll</h3>
<p>Whenever someone wants to start a poll, he / she has to send a <code>start_poll</code> RPC. This procedure contains the poll's question and its hash, computed from the text and a nonce. This hash is then used to build the <strong>poll's Merkle tree</strong> (details to come in a later section). Each node that wants to take part in the poll, has to find a key pair for which the hash of the public key is numerically less then the <code>start_poll</code> <em>genesis</em> hash (the created with the aforementioned RPC). The process is similar to the <code>nodeId</code> generation in S/Kademlia and is used to prevent huge amounts of valid key pairs for a single poll. The <code>start_poll</code> message contains also a TTL (time-to-live) indicating the maximum time allowed to find a valid key pair for the poll. TTL and crypto puzzle difficulty are measures that control the ability of nodes to generate an high number of valid key pairs.</p>
<p><img src="plantuml-images/39b131e2d5b230832898068db3332fd2442e8965.png" alt="" /></p>
<p>The node that starts the poll is responsible of sending the <code>start_poll</code> RPC to other nodes. To do so it has to send the RPC to all nodes that it knows about and sends the same request to other nodes that discovers through recursively call <code>find_node</code> on new nodes that discovers. Another strategy / extension could be to start searching for nodes randomly by generating a random <code>nodeId</code> starting a recursive lookup for that node and sending <code>start_poll</code> requests along the way. Nodes that decide to participate in the poll sends an <code>ack_poll</code> back to the node from which came to know about the poll. This RPC does not contain nodes and means that the node is taking responsibility to forward the <code>start_poll</code> message to its neighbors (all nodes that it knows about or only <span class="math inline"><em>k</em></span> closest neighbors are options). Nodes that do not want to participate in the poll send an <code>nack_poll</code> RPC containing its <span class="math inline"><em>k</em></span> closest nodes.</p>
<p>After the TTL expires, each node participating in the poll has a key pair that can be used to vote the poll.</p>
<h2 id="references" class="unnumbered"> References</h2>
<div id="refs" class="references">
<div id="ref-baumgart2007s">
<p>Baumgart, Ingmar, and Sebastian Mies. 2007. “S/Kademlia: A Practicable Approach Towards Secure Key-Based Routing.” In <em>Parallel and Distributed Systems, 2007 International Conference on</em>, 2:1–8. IEEE.</p>
</div>
<div id="ref-maymounkov2002kademlia">
<p>Maymounkov, Petar, and David Mazieres. 2002. “Kademlia: A Peer-to-Peer Information System Based on the Xor Metric.” In <em>International Workshop on Peer-to-Peer Systems</em>, 53–65. Springer.</p>
</div>
</div>
</body>
</html>
